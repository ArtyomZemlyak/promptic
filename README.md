# promptic
Easy prompt management for python projects

## Concept

Я все думаю над концептом библиотеки. На сколько она вообще нужна и что должна делать.

Изначальные потребности следующие:
- Контекст моделей не безграничный, нужно уметь помещать в него только нужное
- Агенты часто закрытые системы, на которые не повлиять (если это только не собственная разработка), нужно какое-то универсальное решение
- Нужно версионирование промптов

Альтернативы библиотеки:
- Использование несколько вызовов в агента под каждый контекст. Минус: меньше гибкости самого агента
- Использование FC или MCP, агент получает короткую инструкцию, инструменты и может делать что хочет далее. Минус: излишнее кол-во тулзов, необходимость их разворота и поддержки

Концептуальные мысли:
- Все делаем через файлы (контекст, промпт, память, задачи и тд)
- Агент читает только то что нужно в моменте, остальное удаляет из контекста (сам или алгоритмически)

Проблемы:
- Многие агенты сами как-то менеджерят контекст свой. И даже если агет читает файлы последовательно под задачи, то его контекст все равно будет наполняться содержимым этих файлов. А очищение может наступить только при переполнении. То есть, либа поможет, но только частично.
- Многие агенты это закрытые ящики и python либа для них будет бесполезна. Но, можно пойти следующим путем: задача для агента ставится какой-то системой, которая как раз может использовать python (тут все ок); если же python никак не применим, то формат после render_for_llm промтпов итоговый должен быть легко понятен агентам (И тут можно в теории самим промпт заполнять или с помощью нашей либы).

Нюансы относительно текущего использования:
- То что у нас много вариантов формирования итогового контекста это интересно, пока оставим (но не факт что в итоге нам это нужно будет).
- Нужно нацелиться именно на уменьшение контекста подаваемого в ЛЛМ в агента исходным промптом, если смотреть на render_for_llm, то там так сейчас не работает, там просто рендерится весь промпт полностью.

Нужно чтобы библиотека умела делать что-то такое:
Все файлы такие как есть сейчас - это хорошо.
Далее в LLM передается только ключевой промпт, ключевая инструкция, список шагов и уточнения какие-нибудь.
И плюсом где нужно указывается, что вот там смотри подробнее. То есть мы идем file-first промптинг или как-то так.
В итоге это может выглядеть вот так (образный пример основного промпта и инструкций):

```md
Ты ассистент. Инструкции:
- Ты умный
- Ты крутой
- Не пиши глупости

Тебе нужно сделать:
1. Подумать (подробнее - instructions/think.md)
2. Написать промежуточные выводы (подробнее - instructions/semi.md)
3. Написать итоговый вывод (подробнее - instructions/total.md)
4. Добавить медиа (подробнее - instructions/media.md)

Если нужно что-то запоминать пиши сюда: memory (формат: такой-то там)
```
И допустим какой-нибудь instructions/media.md файл:

```md
Список медиа:
1
2
3
4
...

Если хочешь узнать подробности, OCR или транскрипцию конкретного медиа, то заменяй файловое расширение в названии файла медиа на .md и читай этот файл.
```

То есть, вот она иерархичность, которую я подразумевал изначально - иерархичность промпта, контекста, памяти через файлы.
Поэтому нужно делать 003 фичу с переформатированием / дополнением нашей библиотеки.


Разные форматы для blueprint:
- yaml (сейчас везде в примерах)
- jinja2
- md
- json
Нужно уметь поддерживать разные форматы, и все они парсятся в json (вроде у нас такой должен быть внутри в коде)
И сделать все рекурсивным. То есть, у нас есть аля ContextNode, которая содержит в себе либо blueprint, либо yaml, либо md, либо jinja2, либо json. Ну или какие-то другие форматы далее.
Тогда мы можем Абстрагироваться от понятий инструкция, данные, память и все такое. В итоге базовой структурой будет ContextNode и структура из нее в виде сети (про рекурсивность сети пока не понятно).
В итоге мы можем все это комбинировать и каждая нода может быть чем угодно.  


Версионирование
Регистр промптов
Получение конкретного промпта (last версия, конкретная версия)


Итоговая польза для tg-note:
- Легче сортировать промпты (сейчас немного путаюсь что куда закинуть)
- Подгрузка промптов за одну строку кода (сейчас если нужно внедрить что-то во все агенты, то это изменение кода в каждом агенте)
- Версионирование из коробки
Какая еще польза может быть?
- Мне хочется какой-то пользы от самой либы в плане конструирования связей или чего-то такого, какие-то маленькие вещи, но которые упрощают работу с промптами
- Может быть сделать функционал по разбиению одного промпта на несколько
- И чего-то для контекста и памяти
- Плюс учитывать ограничения контекста и как-то динамически что-то выкидывать
- И еще чего-то
- Можно смотреть на потребности других проектов и выписывать что нужно

- кейс tg-note, что нужно вставлять ссылки на .md OCR файлы (то бишь это динамика какая-то)

- Параметры генерации
- Модель, api
-
